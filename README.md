# ML Exercise 4 - Cross Validation | NumPy + Sklearn

This notebook demonstrates how to evaluate ML models using **Train/Test Split**, **K-Fold**, and **Stratified K-Fold Cross-Validation**.

### 🔍 What’s Inside:
- Use `train_test_split()` vs `KFold` vs `StratifiedKFold`
- Evaluate Logistic Regression accuracy
- Visualize method-wise performance comparison

### 🎯 Learning Goal:
Understand why cross-validation gives more robust evaluation compared to a single train/test split.

### 🚀 Extensions:
- Test on multiclass data
- Try Leave-One-Out CV
- Compare different models
