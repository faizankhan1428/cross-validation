# ML Exercise 4 - Cross Validation | NumPy + Sklearn

This notebook demonstrates how to evaluate ML models using **Train/Test Split**, **K-Fold**, and **Stratified K-Fold Cross-Validation**.

### ğŸ” Whatâ€™s Inside:
- Use `train_test_split()` vs `KFold` vs `StratifiedKFold`
- Evaluate Logistic Regression accuracy
- Visualize method-wise performance comparison

### ğŸ¯ Learning Goal:
Understand why cross-validation gives more robust evaluation compared to a single train/test split.

### ğŸš€ Extensions:
- Test on multiclass data
- Try Leave-One-Out CV
- Compare different models
